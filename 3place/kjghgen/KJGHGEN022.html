<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="hbaolong@vip.qq.com" />
  <title>科技共和国EN:Chapter Fifteen Into the Desert</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">科技共和国EN:Chapter Fifteen Into the Desert</h1>
<p class="author">hbaolong@vip.qq.com</p>
</header>
<center>
<a href="/3place/kjghgen">返回首页</a> <a
href="/3place/kjghgen/mingju.html">本书名句</a> <a
href="/3place/kjghgen/memo.html">本书注解</a> <a
href="/3place/kjghgen/index_rich.html">丰富目录</a> <a
href="/3place/kjghgen/index_readcal.html">同读日历</a> <a
href="/3place/kjghgen/index_timeline.html">时间线</a> <a
href="/3place/kjghgen/index_books.html">引用书籍</a> <a
href="/3place/kjghgen/index_words.html">使用字频</a>
<div id="wx_pic" style="margin:0 auto;display:none;">
<img src='/img/logo.png'/>
</div>
</center>
<h4 id="chapter-fifteen-into-the-desert">Chapter Fifteen Into the
Desert</h4>
<p>In late 1906, Francis Galton, a British anthropologist, traveled to
Plymouth, England, in the country’s southwest, where he attended a
livestock fair. His interest was not in purchasing the poultry or cattle
that were available for sale at the market but in studying the ability
of large groups of individuals to correctly make estimates. Nearly eight
hundred visitors at the market had written down estimates of the weight
of a particular ox that was for sale. Each person had to pay six pennies
for a chance to submit their guess and win a prize, which deterred, in
Galton’s words, “practical joking” that might muddy the results of the
experiment. The median estimate of the 787 guesses that Galton received
was 1,207 pounds, which turned out to be within 0.8 percent of the
correct answer of 1,198 pounds. It was a striking result and would
prompt more than a century of research and debate about the wisdom of
crowds and their ability to more accurately make estimates, and indeed
predictions, than a chosen few. For Galton, the experiment pointed to
“the trustworthiness of a democratic judgment.”</p>
<p>But why must we always defer to the wisdom of the crowd when it comes
to allocating scarce capital in a market economy? We seem to have
unintentionally deprived ourselves of the opportunity to engage in a
critical discussion about the businesses and endeavors that ought to
exist, not merely the ventures that could. The wisdom of the crowd at
the height of the rise of Zynga and Groupon in 2011 made its verdict
clear: these were winners that merited further investment. Tens of
billions of dollars were wagered on their continued ascent. But there
was no forum or platform or meaningful opportunity for anyone to
question whether our society’s scarce resources ought to be diverted to
the construction of online games or a more effective aggregator of
coupons and discounts. The market had spoken, so it must be so.</p>
<p>We have, as Michael Sandel of Harvard has argued, been so eager “to
banish notions of the good life from public discourse,” to require that
“citizens leave their moral and spiritual convictions behind when they
enter the public square,” that the void left behind has been filled in
large part by the logic of the market—what Sandel has described as
“market triumphalism.” And the leaders of Silicon Valley have for the
most part been content to submit to this wisdom of the market, allowing
its logic and values to supplant their own. It is our own temerity and
unwillingness to risk the scorn of the crowd that have deprived us of
the opportunity to discuss in any meaningful way what the world that we
inhabit should be and what companies should exist. The prevailing
agnosticism of the modern era, the reluctance to advance a substantive
view about cultural value, or lack thereof, for fear of alienating
anyone, has paved the way for the market to fill the gap.</p>
<p>The drift of the technology world to the concerns of the consumer
both reflected and helped reinforce a certain technological escapism—the
instinct by Silicon Valley to steer away from the most important
problems we face as a society toward what are essentially the minor and
trivial yet solvable inconveniences of everyday consumer life, from
online shopping to food delivery. An entire swath of challenges from
national defense to violent crime, education reform to medical research,
appeared to many to be too intractable, too thorny, and too politically
fraught to address in any real way. Most were content to set the hard
problems aside. Toys, by contrast, did not talk back, hold press
conferences, or fund pressure groups. The tragedy is that it has often
been far easier and more lucrative for Silicon Valley to serve the
consumer than the public, and certainly less risky.</p>
<hr />
<p>• • •</p>
<p>The question of whether science and technology should be deployed to
address violent crime in the United States has always been provocative.
The history of abuses of power by U.S. law enforcement agencies,
including by the FBI under J. Edgar Hoover and others, and incursions
into the private lives of American citizens, is beyond dispute. An FBI
file on the writer James Baldwin had swelled to 1,884 pages by 1974.
Such invasions of personal privacy set the stage for a certain dualism
in the debate over the twentieth century; either technological advances,
including fingerprints, DNA, and later facial recognition systems, were
essential to the difficult and often fruitless task of dismantling
violent criminal networks, or they were the tools by which an
overreaching state would target the powerless and imprison the
innocent.</p>
<p>The next wave of technical breakthroughs, including the deployment of
artificial intelligence to assist police departments, will only fuel
this debate further and is set to reshape our sense of the possible when
it comes to law enforcement and computing. A number of defense
contractors, for example, including BAE Systems, working with the
National Physical Laboratory in the United Kingdom, have developed gait
recognition systems—software programs that are capable of identifying an
individual based on little more than video footage of the person
walking, without any access to an image of the individual’s face. The
technology has been under development for more than a decade and is
improving in accuracy every day. Small flying drones operated by police
departments can now approach a car window and break the glass, allowing
police officers to take an unobstructed shot at someone within.</p>
<p>Our fear, of course, is that these sorts of emerging technologies
might be used and misused, intentionally or otherwise, to detain or harm
the innocent. The possibility of even a single abuse of the software
that we are building must guide its construction and deployment. The
administration of criminal justice is not the place for pragmatism, for
some permissible degree of tolerance for error. François-Marie Arouet,
better known by his pen name, Voltaire, wrote in 1749 that it would be
preferable to set two guilty men free rather than imprison one who is
“virtuous and innocent.” In the eighteenth century, William Blackstone,
one of England’s greatest legal minds, went further, writing that it
would be better to allow “ten guilty persons escape than that one
innocent suffer”—a ratio that would come to structure debate about
errors, permissible or otherwise, in criminal justice. Thomas Starkie, a
British academic and lawyer who was born in the late eighteenth century,
argued for allowing ninety-nine guilty criminals or more to walk free in
order to ensure that a single innocent person would not be wrongfully
imprisoned. The problem is not a fulsome and contentious debate about
the merits of incorporating new technologies in the context of policing
or criminal investigations. Rather, a fear of the unknown is too often
used to abdicate responsibility for navigating any degree of uncertainty
or complexity, and indeed possibility that technology could be
misused.</p>
<p>Attempts to deploy software alongside law enforcement agencies in
American cities have continued to be met with significant skepticism and
distrust. In 2012, Palantir began working with the New Orleans Police
Department to provide officers with access to the same software platform
that had been used by U.S. Special Forces and intelligence analysts in
Afghanistan to predict the placement of roadside bombs and capture those
making them. The challenge for police officers in New Orleans and across
the country was similar to what the U.S. Army had faced in attempting to
disrupt the proliferation of bombs that were killing soldiers: too much
information, and a complete lack of the underlying software architecture
that would allow such information to be integrated and analyzed in any
meaningful way. Criminal investigators and police officers in New
Orleans needed a better system for stitching together the patchwork of
information they had about criminal networks and tackling gun violence.
The use of our platform, known as Gotham, spread quickly across the
police department, with the Times-Picayune describing the system as “a
one-stop shop for pulling up and cross-referencing information,” and
“discovering unseen connections among victims, suspects or
witnesses.”</p>
<p>The critics, however, were swift and fierce. The reaction, indeed,
was visceral for many. Why should New Orleans permit the deployment of a
software system designed for use in a foreign war on the streets of the
city at home? In an essay published in 2018, a policy analyst with the
American Civil Liberties Union wrote that the use of data in the context
of law enforcement was “deeply problematic,” given the threats to the
civil rights and liberties of individuals who might be unfairly and
unconstitutionally targeted by law enforcement as a result of the use of
analytical software by the police. The moral outrage and indignation
were directed against the application of a novel technology instead of
the failure of the city’s government to guard its residents. The country
spent 5 billion to protect soldiers in Afghanistan from the threat of
roadside bombs, but when it came to preventing the loss of American
lives in our nation’s cities, at the hands of the depraved, the mentally
ill, and often extraordinarily well-resourced and ruthless violent
gangs, the collective reaction is more often one of apathy and
resignation.</p>
<p>Other technology firms have attempted, and abandoned, similar
projects involving the use of software and artificial intelligence in
the context of local law enforcement. In June 2020, Amazon decided to
prohibit the use of its widely available and popular facial recognition
software by police departments, after the company faced criticism that
its system might be used to wrongfully target the innocent. That same
month, IBM went even further, announcing that it would abandon all
research and development into facial recognition capabilities. The
company’s chief executive officer sent a letter to Senators Cory Booker
and Kamala Harris, among others, expressing his company’s opposition to
the use of the technology “for mass surveillance, racial profiling,” and
“violations of basic human rights and freedoms.” The letter was
representative of an ascendant form of hollow and meaningless corporate
pronouncement, condemning an evil for which nobody is advocating. The
subtle, interesting, and difficult discussion was not whether the abuse
of such systems was justified but rather whether their proper use had
any role to play in stemming violence in our cities. Thousands of people
are murdered every year in this country. Hundreds of thousands and
arguably millions more live in the shadow of such violence. For many
critics of the use of software by local law enforcement, those lives
hardly seemed to matter much in the moral calculus.</p>
<p>The rest of the country, and many politicians across the United
States, have essentially shrugged when it comes to violent crime,
abandoning any serious efforts to address the problem or take on any
risk with their constituencies or donors in coming up with novel
solutions and experiments in what should be a desperate bid to save
lives. The price imposed on entrants into these areas has become
incredibly high. And the message, implicit and often explicit, to those
in Silicon Valley and across the technology sector has been plain. Steer
clear. It was a deeply cynical response to violence that many of those
in power in the United States have essentially abandoned any
responsibility for addressing. Our representatives in Washington and
elsewhere have simply turned their attention to less controversial
terrain. Vast swaths of the American landscape, from law enforcement to
medicine to education, have become innovation deserts where the Valley
has been told, and often warned repeatedly, not to tread.</p>
<hr />
<p>• • •</p>
<p>The view that advanced technology and software have no place in local
law enforcement is an archetypal “luxury belief,” to use the term of the
author Rob Henderson. Such beliefs are ones that a privileged elite can
afford to take on, almost as a cloak, as the columnist David Brooks of
the New York Times put it, but that strike many as woefully “out of
touch to people in less privileged parts of society.” For those living
under the constant assault of gunfire, for example, the thought of
reducing support and funding for law enforcement struck many as an odd
joke, the sort of campaign that had more to do with advancing a
perception of political victory than actually shaping or advancing any
outcomes on the ground.</p>
<p>The more fundamental issue is that the left establishment has
decided, essentially unilaterally, that it need not be in conversation
or dialogue with the right—that mere engagement with the other is itself
a sign of cultural betrayal. When Peggy Noonan noted in a 2019 essay
that the distaste by the Washington establishment for the current brand
of American populism was, at its core, “almost aesthetic,” she was
absolutely correct in identifying the left’s most pernicious weapon: the
ability to brand an entire swath of political views—on issues ranging
from national security, immigration, abortion, to law enforcement—as
essentially lowbrow and uncouth. This is where Silicon Valley and other
progressives have unfortunately and unwittingly deprived themselves of
power in the cultural conversation. Their refusal to engage with the
political claims and demands of essentially half of the country risks
marginalizing their own agenda.</p>
<p>We have begun to privilege the symbolism of victory, the more
theatrical elements and outward displays that constitute expression of
our own moral superiority, over actual, and often less than visible,
advances and improvements in standards of living and quality of life.
And yet it is the zealous pursuit of those advances and outcomes that
forms the bedrock of the engineer’s approach to the world and the basis
of a technological republic. The risk is that we abandon a moral or
ethical system oriented around results—the outcomes that matter most to
people (less hunger, crime, and disease)—in favor of a far more
performative discourse, where the management of messages around such
outcomes eclipses the importance of the outcomes themselves. And the
reconstruction of a technological republic will, among other things,
require the rebuilding of an ownership society, a founder culture that
came from tech but has the potential to reshape government, where nobody
is entrusted with leadership who does not have a stake in their own
success.</p>
<p>•</p>
<h6 id="阅读日期-2026年01月19日-2026年01月19日-共-1-天">阅读日期：
2026年01月19日-2026年01月19日 共： 1 天</h6>
<script src="https://giscus.app/client.js"
        data-repo="hbaolong/hbaolong.github.io"
        data-repo-id="R_kgDOLetDQg"
        data-category="General"
        data-category-id="DIC_kwDOLetDQs4CfLEl"
        data-mapping="url"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>
<script src="https://giscus.app/client.js"
        data-repo="hbaolong/hbaolong.github.io"
        data-repo-id="R_kgDOLetDQg"
        data-category="General"
        data-category-id="DIC_kwDOLetDQs4CfLEl"
        data-mapping="url"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
