<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="hbaolong@vip.qq.com" />
  <title>统计反思EN:4.7. Practice</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">统计反思EN:4.7. Practice</h1>
<p class="author">hbaolong@vip.qq.com</p>
</header>
<center>
<a href="/3place/tjfsen">返回首页</a> <a
href="/3place/tjfsen/mingju.html">本书名句</a> <a
href="/3place/tjfsen/memo.html">本书注解</a> <a
href="/3place/tjfsen/index_rich.html">丰富目录</a> <a
href="/3place/tjfsen/index_readcal.html">同读日历</a> <a
href="/3place/tjfsen/index_timeline.html">时间线</a> <a
href="/3place/tjfsen/index_books.html">引用书籍</a> <a
href="/3place/tjfsen/index_words.html">使用字频</a>
<div id="wx_pic" style="margin:0 auto;display:none;">
<img src='/img/logo.png'/>
</div>
</center>
<h4 id="practice">4.7. Practice</h4>
<p>Problems are labeled Easy (E), Medium (M), and Hard (H).</p>
<p>4E1. In the model definition below, which line is the likelihood?</p>
<p>yi ~ Normal(μ, σ)</p>
<p>μ ~ Normal(0, 10)</p>
<p>σ ~ Exponential(1)</p>
<p>4E2. In the model definition just above, how many parameters are in
the posterior distribution?</p>
<p>4E3. Using the model definition above, write down the appropriate
form of Bayes’ theorem that includes the proper likelihood and
priors.</p>
<p>4E4. In the model definition below, which line is the linear
model?</p>
<p>yi ~ Normal(µ, σ)</p>
<p>µi = α + βxi</p>
<p>α ~ Normal(0, 10)</p>
<p>β ~ Normal(0, 1)</p>
<p>σ ~ Exponential(2)</p>
<p>4E5. In the model definition just above, how many parameters are in
the posterior distribution?</p>
<p>4M1. For the model definition below, simulate observed y values from
the prior (not the posterior).</p>
<p>yi ~ Normal(µ, σ)</p>
<p>µ ~ Normal(0, 10)</p>
<p>σ ~ Exponential(1)</p>
<p>4M2. Translate the model just above into a quap formula.</p>
<p>4M3. Translate the quap model formula below into a mathematical model
definition.</p>
<p>y ~ dnorm( mu , sigma ),</p>
<p>mu &lt;- a + b*x,</p>
<p>a ~ dnorm( 0 , 10 ),</p>
<p>b ~ dunif( 0 , 1 ),</p>
<p>sigma ~ dexp( 1 )</p>
<p>4M4. A sample of students is measured for height each year for 3
years. After the third year, you want to fit a linear regression
predicting height using year as a predictor. Write down the mathematical
model definition for this regression, using any variable names and
priors you choose. Be prepared to defend your choice of priors.</p>
<p>4M5. Now suppose I remind you that every student got taller each
year. Does this information lead you to change your choice of priors?
How?</p>
<p>4M6. Now suppose I tell you that the variance among heights for
students of the same age is never more than 64cm. How does this lead you
to revise your priors?</p>
<p>4M7. Refit model m4.3 from the chapter, but omit the mean weight xbar
this time. Compare the new model’s posterior to that of the original
model. In particular, look at the covariance among the parameters. What
is different? Then compare the posterior predictions of both models.</p>
<p>4M8. In the chapter, we used 15 knots with the cherry blossom spline.
Increase the number of knots and observe what happens to the resulting
spline. Then adjust also the width of the prior on the weights—change
the standard deviation of the prior and watch what happens. What do you
think the combination of knot number and the prior on the weights
controls?</p>
<p>4H1. The weights listed below were recorded in the !Kung census, but
heights were not recorded for these individuals. Provide predicted
heights and 89% intervals for each of these individuals. That is, fill
in the table below, using model-based predictions.</p>
<p>Individual</p>
<p>weight</p>
<p>expected height</p>
<p>89% interval</p>
<p>1</p>
<p>46.95</p>
<p>2</p>
<p>43.72</p>
<p>3</p>
<p>64.78</p>
<p>4</p>
<p>32.59</p>
<p>5</p>
<p>54.63</p>
<p>4H2. Select out all the rows in the Howell1 data with ages below 18
years of age. If you do it right, you should end up with a new data
frame with 192 rows in it.</p>
<ol type="a">
<li><p>Fit a linear regression to these data, using quap. Present and
interpret the estimates. For every 10 units of increase in weight, how
much taller does the model predict a child gets?</p></li>
<li><p>Plot the raw data, with height on the vertical axis and weight on
the horizontal axis. Super- impose the MAP regression line and 89%
interval for the mean. Also superimpose the 89% interval for predicted
heights.</p></li>
<li><p>What aspects of the model fit concern you? Describe the kinds of
assumptions you would change, if any, to improve the model. You don’t
have to write any new code. Just explain what the model appears to be
doing a bad job of, and what you hypothesize would be a better
model.</p></li>
</ol>
<p>4H3. Suppose a colleague of yours, who works on allometry, glances at
the practice problems just above. Your colleague exclaims, “That’s
silly. Everyone knows that it’s only the logarithm of body weight that
scales with height!” Let’s take your colleague’s advice and see what
happens.</p>
<ol type="a">
<li><p>Model the relationship between height (cm) and the natural
logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544
rows, adults and non-adults. Can you interpret the resulting
estimates?</p></li>
<li><p>Begin with this plot: plot( height ~ weight , data=Howell1 ).
Then use samples from the quadratic approximate posterior of the model
in (a) to superimpose on the plot: (1) the predicted mean height as a
function of weight, (2) the 97% interval for the mean, and (3) the 97%
interval for predicted heights.</p></li>
</ol>
<p>4H4. Plot the prior predictive distribution for the parabolic
polynomial regression model in the chapter. You can modify the code that
plots the linear regression prior predictive distribution. Can you
modify the prior distributions of α, β1 , and β2 so that the prior
predictions stay within the bio- logically reasonable outcome space?
That is to say: Do not try to fit the data by hand. But do try to keep
the curves consistent with what you know about height and weight, before
seeing these exact data.</p>
<p>4H5. Return to data(cherry_blossoms) and model the association
between blossom date (doy) and March temperature (temp). Note that there
are many missing values in both variables. You may consider a linear
model, a polynomial, or a spline on temperature. How well does
temperature trend predict the blossom trend?</p>
<p>4H6. Simulate the prior predictive distribution for the cherry
blossom spline in the chapter. Adjust the prior on the weights and
observe what happens. What do you think the prior on the weights is
doing?</p>
<p>4H8. The cherry blossom spline in the chapter used an intercept α,
but technically it doesn’t require one. The first basis functions could
substitute for the intercept. Try refitting the cherry blossom spline
without the intercept. What else about the model do you need to change
to make this work?</p>
<p>5 The Many Variables andandandand The Spurious Waffles</p>
<p>One of the most reliable sources of waffles in North America, if not
the entire world, is a Waffle House diner. Waffle House is nearly always
open, even just after a hurricane. Most diners invest in disaster
preparedness, including having their own electrical generators. As a
consequence, the United States’ disaster relief agency (FEMA) informally
uses Waffle House as an index of disaster severity.79 If the Waffle
House is closed, that’s a serious event.</p>
<p>It is ironic then that steadfast Waffle House is associated with the
nation’s highest divorce rates (Figure 5.1). States with many Waffle
Houses per person, like Georgia and Alabama, also have some of the
highest divorce rates in the United States. The lowest divorce rates are
found where there are zero Waffle Houses. Could always-available waffles
and hash brown potatoes put marriage at risk?</p>
<p>Probably not. This is an example of a misleading correlation. No one
thinks there is any plausible mechanism by which Waffle House diners
make divorce more likely. Instead, when we see a correlation of this
kind, we immediately start asking about other variables that are really
driving the relationship between waffles and divorce. In this case,
Waffle House began in Georgia in the year 1955. Over time, the diners
spread across the Southern United States, remaining largely within it.
So Waffle House is associated with the South. Divorce is not a uniquely
Southern institution, but the Southern United States has some of the
highest divorce rates in the nation. So it’s probably just an accident
of history that Waffle House and high divorce rates both occur in the
South.</p>
<p>Such accidents are commonplace. It is not surprising that Waffle
House is correlated with divorce, because correlation in general is not
surprising. In large data sets, every pair of variables has a
statistically discernible non-zero correlation.80 But since most
correlations do not indicate causal relationships, we need tools for
distinguishing mere association from evidence of causation. This is why
so much effort is devoted to multiple regression, using more than one
predictor variable to simultaneously model an outcome. Reasons given for
multiple regression models include:</p>
<ol type="1">
<li><p>Statistical “control” for confounds. A confound is something that
misleads us about a causal influence—there will be a more precise
definition in the next chapter. The spurious waffles and divorce
correlation is one type of confound, where southern- ness makes a
variable with no real importance (Waffle House density) appear to be
important. But confounds are diverse. They can hide important effects
just as easily as they can produce false ones.</p></li>
<li><p>Multiple and complex causation. A phenomenon may arise from
multiple simul- taneous causes, and causes can cascade in complex ways.
And since one cause can hide another, they must be measured
simultaneously.</p></li>
</ol>
<p>AR</p>
<p>ME</p>
<p>AL</p>
<p>OK</p>
<p>GA</p>
<p>SC</p>
<p>NJ</p>
<p>Figure 5.1. The number of Waffle House diners per million people is
associated with divorce rate (in the year 2009) within the United
States. Each point is a State. “South- ern” (former Confederate) States
shown in blue. Shaded region is 89% percentile in- terval of the mean.
These data are in data(WaffleDivorce) in the rethinking package.</p>
<p>0 10 20 30 40 50 Waffle Houses per million</p>
<ol start="3" type="1">
<li>Interactions. The importance of one variable may depend upon
another. For ex- ample, plants benefit from both light and water. But in
the absence of either, the other is no benefit at all. Such interactions
occur very often. Effective inference about one variable will often
depend upon consideration of others.</li>
</ol>
<p>In this chapter, we begin to deal with the first of these two, using
multiple regression to deal with simple confounds and to take multiple
measurements of association. You’ll see how to include any arbitrary
number of main effects in your linear model of the Gaussian mean. These
main effects are additive combinations of variables, the simplest type
of multiple vari- able model. We’ll focus on two valuable things these
models can help us with: (1) revealing spurious correlations like the
Waffle House correlation with divorce and (2) revealing impor- tant
correlations that may be masked by unrevealed correlations with other
variables. Along the way, you’ll meet categorical variables, which
require special handling compared to continuous variables.</p>
<p>However, multiple regression can be worse than useless, if we don’t
know how to use it. Just adding variables to a model can do a lot of
damage. In this chapter, we’ll begin to think formally about causal
inference and introduce graphical causal models as a way to design and
interpret regression models. The next chapter continues on this theme,
describing some serious and common dangers of adding predictor
variables, ending with a unifying framework for understanding the
examples in both this chapter and the next.</p>
<p>Rethinking: Causal inference. Despite its central importance, there
is no unified approach to causal inference yet in the sciences. There
are even people who argue that cause does not really exist; it’s just a
psychological illusion.81 And in complex dynamical systems, everything
seems to cause everything else. “Cause” loses intuitive value. About one
thing, however, there is general agreement: Causal inference always
depends upon unverifiable assumptions. Another way to say this is that
it’s always possible to imagine some way in which your inference about
cause is mistaken, no matter how careful the design or analysis. A lot
can be accomplished, despite this barrier.82</p>
<p>13</p>
<p>Marriage rate</p>
<p>23</p>
<p>Figure 5.2. Divorce rate is associated with both marriage rate (left)
and median age at marriage (right). Both predictor variables are
standardized in this example. The average marriage rate across States is
20 per 1000 adults, and the average median age at marriage is 26
years.</p>
<h6 id="阅读日期-2025年12月23日-2025年12月23日-共-1-天">阅读日期：
2025年12月23日-2025年12月23日 共： 1 天</h6>
<script src="https://giscus.app/client.js"
        data-repo="hbaolong/hbaolong.github.io"
        data-repo-id="R_kgDOLetDQg"
        data-category="General"
        data-category-id="DIC_kwDOLetDQs4CfLEl"
        data-mapping="url"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
