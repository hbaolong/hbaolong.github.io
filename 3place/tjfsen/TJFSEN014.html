<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="hbaolong@vip.qq.com" />
  <title>统计反思EN:2.2. Building a model</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">统计反思EN:2.2. Building a model</h1>
<p class="author">hbaolong@vip.qq.com</p>
</header>
<center>
<a href="/3place/tjfsen">返回首页</a> <a
href="/3place/tjfsen/mingju.html">本书名句</a> <a
href="/3place/tjfsen/memo.html">本书注解</a> <a
href="/3place/tjfsen/index_rich.html">丰富目录</a> <a
href="/3place/tjfsen/index_readcal.html">同读日历</a> <a
href="/3place/tjfsen/index_timeline.html">时间线</a> <a
href="/3place/tjfsen/index_books.html">引用书籍</a> <a
href="/3place/tjfsen/index_words.html">使用字频</a>
<div id="wx_pic" style="margin:0 auto;display:none;">
<img src='/img/logo.png'/>
</div>
</center>
<h4 id="building-a-model">2.2. Building a model</h4>
<p>By working with probabilities instead of raw counts, Bayesian
inference is made much easier, but it looks much harder. So in this
section, we follow up on the garden of forking data by presenting the
conventional form of a Bayesian statistical model. The toy example we’ll
use here has the anatomy of a typical statistical analysis, so it’s the
style that you’ll grow accustomed to. But every piece of it can be
mapped onto the garden of forking data. The logic is the same.</p>
<p>Suppose you have a globe representing our planet, the Earth. This
version of the world is small enough to hold in your hands. You are
curious how much of the surface is covered in water. You adopt the
following strategy: You will toss the globe up in the air. When you
catch it, you will record whether or not the surface under your right
index finger is water or land. Then you toss the globe up in the air
again and repeat the procedure.43 This strategy generates a sequence of
samples from the globe. The first nine samples might look like:</p>
<p>W L W W W L W L W</p>
<p>where W indicates water and L indicates land. So in this example you
observe six W (water) observations and three L (land) observations. Call
this sequence of observations the data.</p>
<p>To get the logic moving, we need to make assumptions, and these
assumptions constitute the model. Designing a simple Bayesian model
benefits from a design loop with three steps.</p>
<ol type="1">
<li><p>Data story: Motivate the model by narrating how the data might
arise.</p></li>
<li><p>Update: Educate your model by feeding it the data.</p></li>
<li><p>Evaluate: All statistical models require supervision, leading to
model revision. The next sections walk through these steps, in the
context of the globe tossing evidence.</p></li>
</ol>
<p>2.2.1. A data story. Bayesian data analysis usually means producing a
story for how the data came to be. This story may be descriptive,
specifying associations that can be used to predict outcomes, given
observations. Or it may be causal, a theory of how some events produce
other events. Typically, any story you intend to be causal may also be
descriptive. But many descriptive stories are hard to interpret
causally. But all data stories are complete, in the sense that they are
sufficient for specifying an algorithm for simulating new data. In the
next chapter, you’ll see examples of doing just that, as simulating new
data is useful not only for model criticism but also for model
construction.</p>
<p>You can motivate your data story by trying to explain how each piece
of data is born. This usually means describing aspects of the underlying
reality as well as the sampling process. The data story in this case is
simply a restatement of the sampling process:</p>
<ol type="1">
<li><p>The true proportion of water covering the globe isp.</p></li>
<li><p>A single toss of the globe has a probability p of producing a
water (W) observation. It has a probability 1 - p of producing a land
(L) observation.</p></li>
<li><p>Each toss of the globe is independent of the others.</p></li>
</ol>
<p>The data story is then translated into a formal probability model.
This probability model is easy to build, because the construction
process can be usefully broken down into a series of component
decisions. Before meeting these components, however, it’ll be useful to
visualize how a Bayesian model behaves. After you’ve become acquainted
with how such a model learns from data, we’ll pop the machine open and
investigate its engineering.</p>
<p>Rethinking: The value of storytelling. The data story has value, even
if you quickly abandon it and never use it to build a model or simulate
new observations. Indeed, it is important to eventually discard the
story, because many different stories correspond to the same model. As a
result, showing that a model does a good job does not in turn uniquely
support our data story. Still, the story has value because in trying to
outline the story, often one realizes that additional questions must be
answered. Most data stories are much more specific than are the verbal
hypotheses that inspire data collection. Hypotheses can be vague, such
as “it’s more likely to rain on warm days.” When you are forced to
consider sampling and measurement and make a precise statement of how
temperature predicts rain, many stories and resulting models will be
consistent with the same vague hypothesis. Resolving that ambiguity
often leads to important realizations and model revisions, before any
model is fit to data.</p>
<p>2.2.2. Bayesian updating. Our problem is one ofusing the evidence—the
sequence of globe tosses—to decide among different possible proportions
of water on the globe. These propor- tions are like the conjectured
marbles inside the bag, from earlier in the chapter. Each possi- ble
proportion may be more or less plausible, given the evidence. A Bayesian
model begins with one set ofplausibilities assigned to each of these
possibilities. These are the prior plau- sibilities. Then it updates
them in light of the data, to produce the posterior plausibilities. This
updating process is a kind of learning, called Bayesian updating. The
details of this updating—how it is mechanically achieved—can wait until
later in the chapter. For now, let’s look only at how such a machine
behaves.</p>
<p>For the sake of the example only, let’s program our Bayesian machine
to initially assign the same plausibility to every proportion of water,
every value ofp. We’ll do better than this later. Now look at the
top-left plot in Figure 2.5. The dashed horizontal line represents this
initial plausibility of each possible value of p. After seeing the first
toss, which is a “W,” the model updates the plausibilities to the solid
line. The plausibility of p = 0 has now fallen to exactly zero—the
equivalent of “impossible.” Why? Because we observed at least one speck
of water on the globe, so now we know there is some water. The model
executes this logic automatically. You don’t have it instruct it to
account for this consequence. Probability theory takes care of it for
you, because it is essentially counting paths through the garden of
forking data, as in the previous section.</p>
<p>Likewise, the plausibility of p &gt; 0.5 has increased. This is
because there is not yet any evidence that there is land on the globe,
so the initial plausibilities are modified to be consis- tent with this.
Note however that the relative plausibilities are what matter, and there
isn’t yet much evidence. So the differences in plausibility are not yet
very large. In this way, the amount of evidence seen so far is embodied
in the plausibilities of each value ofp.</p>
<p>In the remaining plots in Figure 2.5, the additional samples from the
globe are intro- ducedto the model, one at a time. Each dashed curve is
just the solid curve from the previous</p>
<p>W L W W W L</p>
<p>n = 2</p>
<p>W L W W W L W L W</p>
<p>n = 5</p>
<p>W L W W W L W L W</p>
<p>0</p>
<p>proportion water</p>
<p>Figure 2.5. How a Bayesian model learns. Each toss of the globe
produces an observation of water (W) or land (L). The model’s estimate
of the pro- portion of water on the globe is a plausibility for every
possible value. The lines and curves in this figure are these
collections of plausibilities. In each plot, previous plausibilities
(dashed curve) are updated in light of the latest observation to produce
a new set ofplausibilities (solid curve).</p>
<p>plot, moving left to right and top to bottom. Every time a “W” is
seen, the peak of the plausi- bility curve moves to the right, towards
larger values ofp. Every time an “L” is seen, it moves the other
direction. The maximum height of the curve increases with each sample,
meaning that fewer values of p amass more plausibility as the amount of
evidence increases. As each new observation is added, the curve is
updated consistent with all previous observations.</p>
<p>Notice that every updated set of plausibilities becomes the initial
plausibilities for the next observation. Every conclusion is the
starting point for future inference. However, this updating process
works backwards, as well as forwards. Given the final set of
plausibilities in the bottom-right plot of Figure 2.5, and knowing the
final observation (W), it is possible to mathematically divide out the
observation, to infer the previous plausibility curve. So the data could
be presented to your model in any order, or all at once even. In most
cases, you will present the data all at once, for the sake of
convenience. But it’s important to realize that this merely represents
abbreviation of an iterated learning process.</p>
<p>2.2.3. Evaluate. The Bayesian model learns in a way that is
demonstrably optimal, provided that it accurately describes the real,
large world. This is to say that your Bayesian machine guarantees
perfect inference within the small world. No other way of using the
available information, beginning with the same state of information,
could do better.</p>
<p>Don’t get too excited about this logical virtue, however. The
calculations may malfunc- tion, so results always have to be checked.
And if there are important differences between the model and reality,
then there is no logical guarantee of large world performance. And even
if the two worlds did match, any particular sample of data could still
be misleading. So it’s worth keeping in mind at least two cautious
principles.</p>
<p>First, the model’s certainty is no guarantee that the model is a good
one. As the amount of data increases, the globe tossing model will grow
increasingly sure of the proportion of water. This means that the curves
in Figure 2.5 will become increasingly narrow and tall, restricting
plausible values within a very narrow range. But models ofall
sorts—Bayesian or not—can be very confident about an inference, even
when the model is seriously misleading. This is because the inferences
are conditional on the model. What your model is telling you is that,
given a commitment to this particular model, it can be very sure that
the plausible values are in a narrow range. Under a different model,
things might look differently. There will be examples in later
chapters.</p>
<p>Second, it is important to supervise and critique your model’s work.
Consider again the fact that the updating in the previous section works
in any order of data arrival. We could shuffle the order of the
observations, as long as six W’s and three L’s remain, and still end up
with the same final plausibility curve. That is only true, however,
because the model assumes that order is irrelevant to inference. When
something is irrelevant to the machine, it won’t affect the inference
directly. But it may affect it indirectly, because the data will depend
upon order. So it is important to check the model’s inferences in light
of aspects of the data it does</p>
<p>not know about. Such checks are an inherently creative enterprise,
left to the analyst and the scientific community. Golems are very bad at
it.</p>
<p>In 3, you’ll see some examples of such checks. For now, note that the
goal is not to test the truth value of the model’s assumptions. We know
the model’s assumptions are never exactly right, in the sense of
matching the true data generating process. Therefore there’s no point in
checking if the model is true. Failure to conclude that a model is false
must be a failure of our imagination, not a success of the model.
Moreover, models do not need to be exactly true in order to produce
highly precise and useful inferences. All manner of small world
assumptions about error distributions and the like can be violated in
the large world, but a model may still produce a perfectly useful
estimate. This is because models are essentially information processing
machines, and there are some surprising aspects of information that
cannot be easily captured by framing the problem in terms of the truth
of assumptions.45</p>
<p>Instead, the objective is to check the model’s adequacy for some
purpose. This usually means asking and answering additional questions,
beyond those that originally constructed the model. Both the questions
and answers will depend upon the scientific context. So it’s hard to
provide general advice. There will be many examples, throughout the
book, and of course the scientific literature is replete with
evaluations of the suitability of models for different jobs—prediction,
comprehension, measurement, and persuasion.</p>
<h6 id="阅读日期-2025年12月07日-2025年12月07日-共-1-天">阅读日期：
2025年12月07日-2025年12月07日 共： 1 天</h6>
<script src="https://giscus.app/client.js"
        data-repo="hbaolong/hbaolong.github.io"
        data-repo-id="R_kgDOLetDQg"
        data-category="General"
        data-category-id="DIC_kwDOLetDQs4CfLEl"
        data-mapping="url"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>
</body>
</html>
